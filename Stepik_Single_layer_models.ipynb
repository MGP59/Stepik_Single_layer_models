{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перцептрон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка необходимых библиотек \n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d as p3\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "from functools import partial\n",
    "from ipywidgets import interact, RadioButtons, IntSlider, FloatSlider, Dropdown, BoundedFloatText\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "random.seed(42) # начальное состояние генератора случайных чисел, чтобы можно было воспроизводить результаты.\n",
    "Data = np.loadtxt(\"data.csv\", delimiter=\",\") \n",
    "data = Data[:,1:]\n",
    "pears = data[:, 2] == 1\n",
    "apples = np.logical_not(pears)\n",
    "plt.scatter(data[apples][:, 0], data[apples][:, 1], color = \"red\")\n",
    "plt.scatter(data[pears][:, 0], data[pears][:, 1], color = \"green\")\n",
    "plt.xlabel(\"yellowness\")\n",
    "plt.ylabel(\"symmetry\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.4698157 ,   3.23248558,   0.        ],\n",
       "       [  0.81542168,  55.36712558,   2.        ],\n",
       "       [  0.80953667,  24.1535617 ,   2.        ],\n",
       "       ...,\n",
       "       [  1.41846631,  64.52214789,   2.        ],\n",
       "       [  0.70537961, 224.63027661,   0.        ],\n",
       "       [  0.46275864, 189.26785296,   2.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте метод vectorized_forward_pass класса Perceptron. Когда вы начнёте решать задачу, вам нужно будет просто скопировать соответствующую функцию, которую вы написали в ноутбуке (без учёта отступов; шаблон в поле ввода ответа уже будет, ориентируйтесь по нему). Сигнатура функции указана в ноутбуке, она остаётся неизменной.\n",
    "\n",
    "n — количество примеров, m — количество входов. Размерность входных данных input_matrix — (n, m), размерность вектора весов — (m, 1), смещение (bias) — отдельно. vectorized_forward_pass должен возвращать массив формы (n, 1), состоящий либо из 0 и 1, либо из True и False.\n",
    "\n",
    "Обратите внимание, необходимо векторизованное решение, то есть без циклов и операторов ветвления. Используйте свойства умножения матриц и возможность эффективно применять какую-нибудь операцию к каждому элементу np.array, чтобы с минимумом кода получить желаемый результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном степе вам нужно реализовать метод train_on_single_example класса Perceptron, который получает на вход один набор входных активаций размерности (m,1) и правильный ответ (число 0 или 1), после чего обновляет веса в соответствии с правилом обучения перцептрона. Когда вы начнёте решать задачу, вам нужно будет просто скопировать соответствующую функцию, которую вы написали в ноутбуке (без учёта отступов; шаблон в поле ввода ответа уже будет, ориентируйтесь по нему). Сигнатура функции указана в ноутбуке, она остаётся неизменной.\n",
    "\n",
    "Обязательно проверяйте размерности на соответствие указанным в задании и в сигнатуре функции!\n",
    "\n",
    "Дополнительное ограничение: в данной функции нельзя использовать операторы ветвления и циклы. Мы не сможем это проверить во всех случаях (но, возможно, ваше решение с циклом не сможет уложиться в отведённый решению период работы), так что ответственность за выполнение этого ограничения ложится на вашу совесть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, w, b):\n",
    "        \"\"\"\n",
    "        Инициализируем наш объект - перцептрон.\n",
    "        w - вектор весов размера (m, 1), где m - количество переменных\n",
    "        b - число\n",
    "        \"\"\"\n",
    "        \n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "    def forward_pass(self, single_input):\n",
    "        \"\"\"\n",
    "        Метод рассчитывает ответ перцептрона при предъявлении одного примера\n",
    "        single_input - вектор примера размера (m, 1).\n",
    "        Метод возвращает число (0 или 1) или boolean (True/False)\n",
    "        \"\"\"\n",
    "        \n",
    "        result = 0\n",
    "        for i in range(0, len(self.w)):\n",
    "            result += self.w[i] * single_input[i]\n",
    "        result += self.b\n",
    "        \n",
    "        if result > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def vectorized_forward_pass(self, input_matrix):\n",
    "        \"\"\"\n",
    "        Метод рассчитывает ответ перцептрона при предъявлении набора примеров\n",
    "        input_matrix - матрица примеров размера (n, m), каждая строка - отдельный пример,\n",
    "        n - количество примеров, m - количество переменных\n",
    "        Возвращает вертикальный вектор размера (n, 1) с ответами перцептрона\n",
    "        (элементы вектора - boolean или целые числа (0 или 1))\n",
    "        \"\"\"\n",
    "        \n",
    "        column_ones = np.ones((input_matrix.shape[0], 1))\n",
    "        inp = np.hstack((input_matrix, column_ones))\n",
    "        w = np.vstack((np.array(self.w), [[self.b]]))\n",
    "        res = np.dot(inp, w) \n",
    "        res[0] += self.b\n",
    "        return res > 0\n",
    "    \n",
    "    def train_on_single_example(self, example, y):\n",
    "        \"\"\"\n",
    "        принимает вектор активации входов example формы (m, 1) \n",
    "        и правильный ответ для него (число 0 или 1 или boolean),\n",
    "        обновляет значения весов перцептрона в соответствии с этим примером\n",
    "        и возвращает размер ошибки, которая случилась на этом примере до изменения весов (0 или 1)\n",
    "        (на её основании мы потом построим интересный график)\n",
    "        \"\"\"\n",
    "\n",
    "        predict = self.w.T@example+self.b > 0\n",
    "        error = y - predict\n",
    "        self.w = self.w + error*example\n",
    "        self.b = self.b + error\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_perceptron(m):\n",
    "    \"\"\"Создаём перцептрон со случайными весами и m входами\"\"\"\n",
    "    w = np.random.random((m, 1))\n",
    "    return Perceptron(w, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_v_f_p(n, m):\n",
    "    \"\"\"\n",
    "    Расчитывает для перцептрона с m входами\n",
    "    с помощью методов forward_pass и vectorized_forward_pass\n",
    "    n ответов перцептрона на случайных данных.\n",
    "    Возвращает время, затраченное vectorized_forward_pass и forward_pass\n",
    "    на эти расчёты.\n",
    "    \"\"\"\n",
    "    \n",
    "    p = create_perceptron(m)\n",
    "    input_m = np.random.random_sample((n, m))\n",
    "    \n",
    "    start = time.time() \n",
    "    vec = p.vectorized_forward_pass(input_m)\n",
    "    end = time.time() \n",
    "    vector_time = end - start\n",
    "    \n",
    "    start = time.time() \n",
    "    for i in range(0, n):\n",
    "        p.forward_pass(input_m[i]) \n",
    "    end = time.time() \n",
    "    plain_time = end - start\n",
    "\n",
    "    return [vector_time, plain_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03ac663058f4a54954cfa0a54b00e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='n', options=('1', '10', '100'), value='1'), RadioButtons(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mean_execution_time(n, m, trials=100):\n",
    "    \"\"\"среднее время выполнения forward_pass и vectorized_forward_pass за trials испытаний\"\"\"\n",
    "    \n",
    "    return np.array([test_v_f_p(m, n) for _ in range(trials)]).mean(axis=0)\n",
    "\n",
    "def plot_mean_execution_time(n, m):\n",
    "    \"\"\"рисует графики среднего времени выполнения forward_pass и vectorized_forward_pass\"\"\"\n",
    "    \n",
    "    mean_vectorized, mean_plain = mean_execution_time(int(n), int(m))\n",
    "    p1 = plt.bar([0], mean_vectorized, color='g')\n",
    "    p2 = plt.bar([1], mean_plain, color='r')\n",
    "\n",
    "    plt.ylabel(\"Time spent\")\n",
    "    plt.yticks(np.arange(0, mean_plain))\n",
    "\n",
    "    plt.xticks(range(0,1))\n",
    "    plt.legend((\"vectorized\",\"non - vectorized\"))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_mean_execution_time, \n",
    "            n=RadioButtons(options=[\"1\", \"10\", \"100\"]),\n",
    "            m=RadioButtons(options=[\"1\", \"10\", \"100\"], separator=\" \"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение перцептрона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, w, b):\n",
    "        \"\"\"\n",
    "        Инициализируем наш объект - перцептрон.\n",
    "        w - вектор весов размера (m, 1), где m - количество переменных\n",
    "        b - число\n",
    "        \"\"\"\n",
    "        \n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "    def forward_pass(self, single_input):\n",
    "        \"\"\"\n",
    "        Метод рассчитывает ответ перцептрона при предъявлении одного примера\n",
    "        single_input - вектор примера размера (m, 1).\n",
    "        Метод возвращает число (0 или 1) или boolean (True/False)\n",
    "        \"\"\"\n",
    "        \n",
    "        result = 0\n",
    "        for i in range(0, len(self.w)):\n",
    "            result += self.w[i] * single_input[i]\n",
    "        result += self.b\n",
    "        \n",
    "        if result > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def vectorized_forward_pass(self, input_matrix):\n",
    "        \"\"\"\n",
    "        Метод рассчитывает ответ перцептрона при предъявлении набора примеров\n",
    "        input_matrix - матрица примеров размера (n, m), каждая строка - отдельный пример,\n",
    "        n - количество примеров, m - количество переменных\n",
    "        Возвращает вертикальный вектор размера (n, 1) с ответами перцептрона\n",
    "        (элементы вектора - boolean или целые числа (0 или 1))\n",
    "        \"\"\"\n",
    "        \n",
    "        column_ones = np.ones((input_matrix.shape[0], 1))\n",
    "        inp = np.hstack((input_matrix, column_ones))\n",
    "        w = np.vstack((np.array(self.w), [[self.b]]))\n",
    "        res = np.dot(inp, w) \n",
    "        res[0] += self.b\n",
    "        return res > 0\n",
    "    \n",
    "    def train_on_single_example(self, example, y):\n",
    "        \"\"\"\n",
    "        принимает вектор активации входов example формы (m, 1) \n",
    "        и правильный ответ для него (число 0 или 1 или boolean),\n",
    "        обновляет значения весов перцептрона в соответствии с этим примером\n",
    "        и возвращает размер ошибки, которая случилась на этом примере до изменения весов (0 или 1)\n",
    "        (на её основании мы потом построим интересный график)\n",
    "        \"\"\"\n",
    "\n",
    "        predict = self.w.T@example+self.b > 0\n",
    "        error = y - predict\n",
    "        self.w = self.w + error*example\n",
    "        self.b = self.b + error\n",
    "        return error\n",
    "    \n",
    "    def train_until_convergence(self, input_matrix, y, max_steps=1e8):\n",
    "        \"\"\"\n",
    "        input_matrix - матрица входов размера (n, m),\n",
    "        y - вектор правильных ответов размера (n, 1) (y[i] - правильный ответ на пример input_matrix[i]),\n",
    "        max_steps - максимальное количество шагов.\n",
    "        Применяем train_on_single_example, пока не перестанем ошибаться или до умопомрачения.\n",
    "        Константа max_steps - наше понимание того, что считать умопомрачением.\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        errors = 1\n",
    "        while errors and i < max_steps:\n",
    "            i += 1\n",
    "            errors = 0\n",
    "            for example, answer in zip(input_matrix, y):\n",
    "                example = example.reshape((example.size, 1))\n",
    "                error = self.train_on_single_example(example, answer)\n",
    "                errors += int(error)  # int(True) = 1, int(False) = 0, так что можно не делать if"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(coefs):\n",
    "    \"\"\"\n",
    "    рисует разделяющую прямую, соответствующую весам, переданным в coefs = (weights, bias), \n",
    "    где weights - ndarray формы (2, 1), bias - число\n",
    "    \"\"\"\n",
    "    w, bias = coefs\n",
    "    a, b = - w[0][0] / w[1][0], - bias / w[1][0]\n",
    "    xx = np.linspace(*plt.xlim())\n",
    "    line.set_data(xx, a*xx + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_by_step_weights(p, input_matrix, y, max_steps=1e6):\n",
    "    \"\"\"\n",
    "    обучает перцептрон последовательно на каждой строчке входных данных, \n",
    "    возвращает обновлённые веса при каждом их изменении\n",
    "    p - объект класса Perceptron\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    errors = 1\n",
    "    while errors and i < max_steps:\n",
    "        i += 1\n",
    "        errors = 0\n",
    "        for example, answer in zip(input_matrix, y):\n",
    "            example = example.reshape((example.size, 1))\n",
    "            \n",
    "            error = p.train_on_single_example(example, answer)\n",
    "            errors += error  # здесь мы упадём, если вы забыли вернуть размер ошибки из train_on_single_example\n",
    "            if error:  # будем обновлять положение линии только тогда, когда она изменила своё положение\n",
    "                yield p.w, p.b\n",
    "                \n",
    "    for _ in range(20): yield p.w, p.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:,\" width=\"0\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib nbagg\n",
    "\n",
    "np.random.seed(1)\n",
    "fig = plt.figure()\n",
    "plt.scatter(data[apples][:, 0], data[apples][:, 1], color = \"red\", marker=\".\", label=\"Apples\")\n",
    "plt.scatter(data[pears][:, 0], data[pears][:, 1], color = \"green\", marker=\".\", label=\"Pears\")\n",
    "plt.xlabel(\"yellowness\")\n",
    "plt.ylabel(\"symmetry\")\n",
    "line, = plt.plot([], [], color=\"black\", linewidth=2)  # создаём линию, которая будет показывать границу разделения\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "perceptron_for_weights_line = create_perceptron(2)  # создаём перцептрон нужной размерности со случайными весами\n",
    "\n",
    "from functools import partial\n",
    "weights_ani = partial(\n",
    "    step_by_step_weights, p=perceptron_for_weights_line, input_matrix=data[:, :-1], y=data[:, -1][:,np.newaxis]\n",
    ")  # про partial почитайте на https://docs.python.org/3/library/functools.html#functools.partial\n",
    "\n",
    "ani = FuncAnimation(fig, func=plot_line, frames=weights_ani, blit=False, interval=10, repeat=True)\n",
    "# если Jupyter не показывает вам анимацию - раскомментируйте строчку ниже и посмотрите видео\n",
    "# ani.save(\"perceptron_seeking_for_solution.mp4\", fps=15)\n",
    "plt.show()\n",
    "\n",
    "## Не забудьте остановить генерацию новых картинок, прежде чем идти дальше (кнопка \"выключить\" в правом верхнем углу графика)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_by_step_errors(p, input_matrix, y, max_steps=1e6):\n",
    "    \"\"\"\n",
    "    обучает перцептрон последовательно на каждой строчке входных данных, \n",
    "    на каждом шаге обучения запоминает количество неправильно классифицированных примеров\n",
    "    и возвращает список из этих количеств\n",
    "    \"\"\"\n",
    "    def count_errors():\n",
    "        return np.abs(p.vectorized_forward_pass(input_matrix).astype(np.int) - y).sum()\n",
    "    errors_list = [count_errors()]\n",
    "    i = 0\n",
    "    errors = 1\n",
    "    while errors and i < max_steps:\n",
    "        i += 1\n",
    "        errors = 0\n",
    "        for example, answer in zip(input_matrix, y):\n",
    "            example = example.reshape((example.size, 1))\n",
    "            \n",
    "            error = p.train_on_single_example(example, answer)\n",
    "            errors += error\n",
    "            errors_list.append(count_errors())\n",
    "    return errors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 4 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-2ba06f65e5eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mperceptron_for_misclassification\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_perceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0merrors_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep_by_step_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperceptron_for_misclassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrors_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of errors\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-7a62be866e6b>\u001b[0m in \u001b[0;36mstep_by_step_errors\u001b[1;34m(p, input_matrix, y, max_steps)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_single_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0merrors\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0merrors_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0merrors_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-7a62be866e6b>\u001b[0m in \u001b[0;36mcount_errors\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \"\"\"\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcount_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorized_forward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0merrors_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcount_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-b8c8560c35fc>\u001b[0m in \u001b[0;36mvectorized_forward_pass\u001b[1;34m(self, input_matrix)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mcolumn_ones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_ones\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 4 dimension(s)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "perceptron_for_misclassification = create_perceptron(2)\n",
    "errors_list = step_by_step_errors(perceptron_for_misclassification, input_matrix=data[:, :-1], y=data[:, -1][:,np.newaxis])\n",
    "plt.plot(errors_list);\n",
    "plt.ylabel(\"Number of errors\")\n",
    "plt.xlabel(\"Algorithm step number\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(p):\n",
    "    \"\"\"возвращает вектор из всех весов перцептрона, включая смещение\"\"\"\n",
    "    v = np.array(list(p.w.ravel()) + [p.b])\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_by_step_distances(p, ideal, input_matrix, y, max_steps=1e6):\n",
    "    \"\"\"обучает перцептрон p и записывает каждое изменение расстояния от текущих весов до ideal\"\"\"\n",
    "    distances = [norm(get_vector(p) - ideal)]\n",
    "    i = 0\n",
    "    errors = 1\n",
    "    while errors and i < max_steps:\n",
    "        i += 1\n",
    "        errors = 0\n",
    "        for example, answer in zip(input_matrix, y):\n",
    "            example = example.reshape((example.size, 1))\n",
    "            \n",
    "            error = p.train_on_single_example(example, answer)\n",
    "            errors += error\n",
    "            if error:\n",
    "                distances.append(norm(get_vector(p) - ideal))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-9fd4329bfbc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mideal_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mideal_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_until_convergence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mideal_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mideal_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-b8c8560c35fc>\u001b[0m in \u001b[0;36mtrain_until_convergence\u001b[1;34m(self, input_matrix, y, max_steps)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mexample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mexample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_single_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# int(True) = 1, int(False) = 0, так что можно не делать if\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-b8c8560c35fc>\u001b[0m in \u001b[0;36mtrain_on_single_example\u001b[1;34m(self, example, y)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \"\"\"\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "init_weights = np.random.random_sample(3)\n",
    "w, b = init_weights[:-1].reshape((2, 1)), init_weights[-1]\n",
    "ideal_p = Perceptron(w.copy(), b.copy())\n",
    "ideal_p.train_until_convergence(data[:, :-1], data[:, -1][:,np.newaxis])\n",
    "ideal_weights = get_vector(ideal_p)\n",
    "\n",
    "new_p = Perceptron(w.copy(), b.copy())\n",
    "distances = step_by_step_distances(new_p, ideal_weights, data[:, :-1], data[:, -1][:,np.newaxis])\n",
    "\n",
    "plt.xlabel(\"Number of weight updates\")\n",
    "plt.ylabel(\"Distance between good and current weights\")\n",
    "plt.plot(distances);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим разные полезные функции\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"сигмоидальная функция, работает и с числами, и с векторами (поэлементно)\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    \"\"\"производная сигмоидальной функции, работает и с числами, и с векторами (поэлементно)\"\"\"\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \n",
    "    def __init__(self, weights, activation_function=sigmoid, activation_function_derivative=sigmoid_prime):\n",
    "        \"\"\"\n",
    "        weights - вертикальный вектор весов нейрона формы (m, 1), weights[0][0] - смещение\n",
    "        activation_function - активационная функция нейрона, сигмоидальная функция по умолчанию\n",
    "        activation_function_derivative - производная активационной функции нейрона\n",
    "        \"\"\"\n",
    "        \n",
    "        assert weights.shape[1] == 1, \"Incorrect weight shape\"\n",
    "        \n",
    "        self.w = weights\n",
    "        self.activation_function = activation_function\n",
    "        self.activation_function_derivative = activation_function_derivative\n",
    "        \n",
    "    def forward_pass(self, single_input):\n",
    "        \"\"\"\n",
    "        активационная функция логистического нейрона\n",
    "        single_input - вектор входов формы (m, 1), \n",
    "        первый элемент вектора single_input - единица (если вы хотите учитывать смещение)\n",
    "        \"\"\"\n",
    "        \n",
    "        result = 0\n",
    "        for i in range(self.w.size):\n",
    "            result += float(self.w[i] * single_input[i])\n",
    "        return self.activation_function(result)\n",
    "    \n",
    "    def summatory(self, input_matrix):\n",
    "        \"\"\"\n",
    "        Вычисляет результат сумматорной функции для каждого примера из input_matrix. \n",
    "        input_matrix - матрица примеров размера (n, m), каждая строка - отдельный пример,\n",
    "        n - количество примеров, m - количество переменных.\n",
    "        Возвращает вектор значений сумматорной функции размера (n, 1).\n",
    "        \"\"\"\n",
    "        return input_matrix@self.w \n",
    "    \n",
    "    def activation(self, summatory_activation):\n",
    "        \"\"\"\n",
    "        Вычисляет для каждого примера результат активационной функции,\n",
    "        получив на вход вектор значений сумматорной функций\n",
    "        summatory_activation - вектор размера (n, 1), \n",
    "        где summatory_activation[i] - значение суммматорной функции для i-го примера.\n",
    "        Возвращает вектор размера (n, 1), содержащий в i-й строке \n",
    "        значение активационной функции для i-го примера.\n",
    "        \"\"\"\n",
    "        return np.array(list(map(lambda x:  1/(1+np.exp(-x)), summatory_activation)))  \n",
    "    \n",
    "    def vectorized_forward_pass(self, input_matrix):\n",
    "        \"\"\"\n",
    "        Векторизованная активационная функция логистического нейрона.\n",
    "        input_matrix - матрица примеров размера (n, m), каждая строка - отдельный пример,\n",
    "        n - количество примеров, m - количество переменных.\n",
    "        Возвращает вертикальный вектор размера (n, 1) с выходными активациями нейрона\n",
    "        (элементы вектора - float)\n",
    "        \"\"\"\n",
    "        return self.activation(self.summatory(input_matrix)) \n",
    "        \n",
    "    def SGD(self, X, y, batch_size, learning_rate=0.1, eps=1e-6, max_steps=200):\n",
    "        \"\"\"\n",
    "        Внешний цикл алгоритма градиентного спуска.\n",
    "        X - матрица входных активаций (n, m)\n",
    "        y - вектор правильных ответов (n, 1)\n",
    "        \n",
    "        learning_rate - константа скорости обучения\n",
    "        batch_size - размер батча, на основании которого \n",
    "        рассчитывается градиент и совершается один шаг алгоритма\n",
    "        \n",
    "        eps - критерий остановки номер один: если разница между значением целевой функции \n",
    "        до и после обновления весов меньше eps - алгоритм останавливается. \n",
    "        Вторым вариантом была бы проверка размера градиента, а не изменение функции,\n",
    "        что будет работать лучше - неочевидно. В заданиях используйте первый подход.\n",
    "        \n",
    "        max_steps - критерий остановки номер два: если количество обновлений весов \n",
    "        достигло max_steps, то алгоритм останавливается\n",
    "        \n",
    "        Метод возвращает 1, если отработал первый критерий остановки (спуск сошёлся) \n",
    "        и 0, если второй (спуск не достиг минимума за отведённое время).\n",
    "        \"\"\"\n",
    "        \n",
    "        count = 0\n",
    "        res = 1\n",
    "        xcom = np.column_stack((X, y))\n",
    "        while count < max_steps:\n",
    "            np.random.shuffle(xcom)\n",
    "            samplex = xcom[0:batch_size, : -1]\n",
    "            sampley = np.array(list([el[-1]] for el in xcom[0:batch_size]))\n",
    "            res = self.update_mini_batch(samplex,sampley,learning_rate,eps) \n",
    "            if res: \n",
    "                return 1\n",
    "            count += 1\n",
    "        return res\n",
    "    \n",
    "    def update_mini_batch(self, X, y, learning_rate, eps):\n",
    "        \"\"\"\n",
    "        X - матрица размера (batch_size, m)\n",
    "        y - вектор правильных ответов размера (batch_size, 1)\n",
    "        learning_rate - константа скорости обучения\n",
    "        eps - критерий остановки номер один: если разница между значением целевой функции \n",
    "        до и после обновления весов меньше eps - алгоритм останавливается. \n",
    "        \n",
    "        Рассчитывает градиент (не забывайте использовать подготовленные заранее внешние функции) \n",
    "        и обновляет веса нейрона. Если ошибка изменилась меньше, чем на eps - возвращаем 1, \n",
    "        иначе возвращаем 0.\n",
    "        \"\"\"\n",
    "        J_old = J_quadratic(self, X, y) \n",
    "        grad = compute_grad_analytically(self, X, y)  \n",
    "        self.w -= learning_rate * grad  \n",
    "        j_new = J_quadratic(self, X, y)    \n",
    "        if np.abs(J_old - j_new) <= eps:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J_quadratic(neuron, X, y):\n",
    "    \"\"\"\n",
    "    Оценивает значение квадратичной целевой функции.\n",
    "    Всё как в лекции, никаких хитростей.\n",
    "\n",
    "    neuron - нейрон, у которого есть метод vectorized_forward_pass, предсказывающий значения на выборке X\n",
    "    X - матрица входных активаций (n, m)\n",
    "    y - вектор правильных ответов (n, 1)\n",
    "        \n",
    "    Возвращает значение J (число)\n",
    "    \"\"\"\n",
    "    \n",
    "    assert y.shape[1] == 1, 'Incorrect y shape'\n",
    "    \n",
    "    return 0.5 * np.mean((neuron.vectorized_forward_pass(X) - y) ** 2)\n",
    "\n",
    "def J_quadratic_derivative(y, y_hat):\n",
    "    \"\"\"\n",
    "    Вычисляет вектор частных производных целевой функции по каждому из предсказаний.\n",
    "    y_hat - вертикальный вектор предсказаний,\n",
    "    y - вертикальный вектор правильных ответов,\n",
    "    \n",
    "    В данном случае функция смехотворно простая, но если мы захотим поэкспериментировать \n",
    "    с целевыми функциями - полезно вынести эти вычисления в отдельный этап.\n",
    "    \n",
    "    Возвращает вектор значений производной целевой функции для каждого примера отдельно.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert y_hat.shape == y.shape and y_hat.shape[1] == 1, 'Incorrect shapes'\n",
    "    \n",
    "    return (y_hat - y) / len(y)\n",
    "    \n",
    "def compute_grad_analytically(neuron, X, y, J_prime=J_quadratic_derivative):\n",
    "    \"\"\"\n",
    "    Аналитическая производная целевой функции\n",
    "    neuron - объект класса Neuron\n",
    "    X - вертикальная матрица входов формы (n, m), на которой считается сумма квадратов отклонений\n",
    "    y - правильные ответы для примеров из матрицы X\n",
    "    J_prime - функция, считающая производные целевой функции по ответам\n",
    "    \n",
    "    Возвращает вектор размера (m, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Вычисляем активации\n",
    "    # z - вектор результатов сумматорной функции нейрона на разных примерах\n",
    "    \n",
    "    z = neuron.summatory(X)\n",
    "    y_hat = neuron.activation(z)\n",
    "\n",
    "    # Вычисляем нужные нам частные производные\n",
    "    dy_dyhat = J_prime(y, y_hat)\n",
    "    dyhat_dz = neuron.activation_function_derivative(z)\n",
    "    \n",
    "    # осознайте эту строчку:\n",
    "    dz_dw = X\n",
    "\n",
    "    # а главное, эту:\n",
    "    grad = ((dy_dyhat * dyhat_dz).T).dot(dz_dw)\n",
    "    \n",
    "    # можно было написать в два этапа. Осознайте, почему получается одно и то же\n",
    "    # grad_matrix = dy_dyhat * dyhat_dz * dz_dw\n",
    "    # grad = np.sum(, axis=0)\n",
    "    \n",
    "    # Сделаем из горизонтального вектора вертикальный\n",
    "    grad = grad.T\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас мы проверим, правильно ли считаются производные целевой функции: мы реализуем подсчёт частных производных по определению, как\n",
    "∂f∂xi=f(x1,…,xi−1,xi+Δx,xi+1,…,xd)−f(x1,…,xd)Δx.\n",
    "Это не определение, в определении был бы limΔx→0! Но если мы возьмём достаточно малое Δx, то приближение будет неплохим.\n",
    "\n",
    "Иными словами, мы посчитаем целевую функцию, чуть-чуть поменяем какой-нибудь вес, после этого посчитаем целевую функцию еще раз, дальше применяем определение, то есть разделим разницу в целевой функции на изменение веса.\n",
    "\n",
    "После этого можно будет сравнить результаты, полученные с помощью аналитического и численного метода: они не должны сильно отличаться.\n",
    "\n",
    "Вы уже должны догадываться, почему мы не можем всегда обходиться только лишь численным нахождением производной, но пример, непосредственно это иллюстрирующий, появится на следующей неделе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad_numerically(neuron, X, y, J=J_quadratic, eps=10e-2):\n",
    "    \"\"\"\n",
    "    Численная производная целевой функции\n",
    "    neuron - объект класса Neuron\n",
    "    X - вертикальная матрица входов формы (n, m), на которой считается сумма квадратов отклонений\n",
    "    y - правильные ответы для тестовой выборки X\n",
    "    J - целевая функция, градиент которой мы хотим получить\n",
    "    eps - размер $\\delta w$ (малого изменения весов)\n",
    "    \"\"\"\n",
    "\n",
    "    initial_cost = J(neuron, X, y)\n",
    "    w_0 = neuron.w\n",
    "    num_grad = np.zeros(w_0.shape)\n",
    "    \n",
    "    for i in range(len(w_0)):\n",
    "        \n",
    "        old_wi = neuron.w[i].copy()\n",
    "        # Меняем вес\n",
    "        neuron.w[i] += eps\n",
    "        \n",
    "        # Считаем новое значение целевой функции и вычисляем приближенное значение градиента\n",
    "        num_grad[i] = (J(neuron, X, y) - initial_cost)/eps\n",
    "        \n",
    "        # Возвращаем вес обратно. Лучше так, чем -= eps, чтобы не накапливать ошибки округления\n",
    "        neuron.w[i] = old_wi\n",
    "            \n",
    "    # проверим, что не испортили нейрону веса своими манипуляциями\n",
    "    assert np.allclose(neuron.w, w_0), \"МЫ ИСПОРТИЛИ НЕЙРОНУ ВЕСА\"\n",
    "    return num_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Численный градиент: \n",
      " [[-0.00545152]\n",
      " [-0.00543643]\n",
      " [ 0.08950208]]\n",
      "Аналитический градиент: \n",
      " [[-0.00533251]\n",
      " [-0.00529075]\n",
      " [ 0.13592882]]\n"
     ]
    }
   ],
   "source": [
    "# Подготовим данные\n",
    "\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "X = np.hstack((np.ones((len(y), 1)), X))\n",
    "y = y.reshape((len(y), 1)) # Обратите внимание на эту очень противную и важную строчку\n",
    "\n",
    "\n",
    "# Создадим нейрон\n",
    "\n",
    "w = np.random.random((X.shape[1], 1))\n",
    "neuron = Neuron(w, activation_function=sigmoid, activation_function_derivative=sigmoid_prime)\n",
    "\n",
    "# Посчитаем пример\n",
    "num_grad = compute_grad_numerically(neuron, X, y, J=J_quadratic)\n",
    "an_grad = compute_grad_analytically(neuron, X, y, J_prime=J_quadratic_derivative)\n",
    "\n",
    "print(\"Численный градиент: \\n\", num_grad)\n",
    "print(\"Аналитический градиент: \\n\", an_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Вроде бы похоже\", но это не очень удовлетворительный ответ. Давайте посмотрим, как меняется наше приближение в зависимости от ε. Посчитаем для разных ε модуль разности этих двух градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6b99bed1024551ab44a9ad211dcfc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='eps', options=('3', '1', '0.1', '0.001', '0.0001'), value='3')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_grad_diff(eps):\n",
    "    num_grad = compute_grad_numerically(neuron, X, y, J=J_quadratic, eps=float(eps))\n",
    "    an_grad = compute_grad_analytically(neuron, X, y, J_prime=J_quadratic_derivative)\n",
    "    print(np.linalg.norm(num_grad-an_grad))\n",
    "    \n",
    "interact(print_grad_diff, \n",
    "            eps=RadioButtons(options=[\"3\", \"1\", \"0.1\", \"0.001\", \"0.0001\"]), separator=\" \");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad_numerically_2(neuron, X, y, J=J_quadratic, eps=10e-2):\n",
    "    \"\"\"\n",
    "    Численная производная целевой функции.\n",
    "    neuron - объект класса Neuron с вертикальным вектором весов w,\n",
    "    X - вертикальная матрица входов формы (n, m), на которой считается сумма квадратов отклонений,\n",
    "    y - правильные ответы для тестовой выборки X,\n",
    "    J - целевая функция, градиент которой мы хотим получить,\n",
    "    eps - размер $\\delta w$ (малого изменения весов).\n",
    "    \"\"\"\n",
    "    \n",
    "    w_0 = neuron.w.copy() \n",
    "    num_grad = np.zeros(w_0.shape) \n",
    "    for i in range(len(w_0)): \n",
    "        neuron.w = w_0.copy() \n",
    "        # Меняем вес\n",
    "        neuron.w[i] += eps\n",
    "        # Считаем новое значение целевой функции и вычисляем приближенное значение градиента\n",
    "        w_plus_eps = J(neuron, X, y) \n",
    "        neuron.w = w_0.copy() \n",
    "        neuron.w[i] -= eps\n",
    "        w_minus_eps = J(neuron, X, y) \n",
    "        neuron.w = w_0.copy() \n",
    "        num_grad[i] = (w_plus_eps - w_minus_eps)/(2*eps)\n",
    "    return num_grad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, к какому результату привели ваши эксперименты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bdd3c3257a40a087f0d1d4f15b99be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='eps', options=('3', '1', '0.1', '0.001', '0.0001'), value='3')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_grad_diff_2(eps):\n",
    "    num_grad = compute_grad_numerically_2(neuron, X, y, J=J_quadratic, eps=float(eps))\n",
    "    an_grad = compute_grad_analytically(neuron, X, y, J_prime=J_quadratic_derivative)\n",
    "    print(np.linalg.norm(num_grad-an_grad))\n",
    "    \n",
    "interact(print_grad_diff_2, \n",
    "            eps=RadioButtons(options=[\"3\", \"1\", \"0.1\", \"0.001\", \"0.0001\"]), separator=\" \");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J_by_weights(weights, X, y, bias):\n",
    "    \"\"\"\n",
    "    Посчитать значение целевой функции для нейрона с заданными весами.\n",
    "    Только для визуализации\n",
    "    \"\"\"\n",
    "    new_w = np.hstack((bias, weights)).reshape((3,1))\n",
    "    return J_quadratic(Neuron(new_w), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30ce25aa6d443f28ed776fe384e8177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, continuous_update=False, description='fixed_bias', max=40.0, min=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "max_b = 40\n",
    "min_b = -40\n",
    "max_w1 = 40\n",
    "min_w1 = -40\n",
    "max_w2 = 40\n",
    "min_w2 = -40\n",
    "\n",
    "g_bias = 0 # график номер 2 будет при первой генерации по умолчанию иметь то значение b, которое выставлено в первом\n",
    "X_corrupted = X.copy()\n",
    "y_corrupted = y.copy()\n",
    "\n",
    "@interact(fixed_bias=FloatSlider(min=min_b, max=max_b, continuous_update=False), \n",
    "          mixing=FloatSlider(min=0, max=1, continuous_update=False, value=0),\n",
    "          shifting=FloatSlider(min=0, max=1, continuous_update=False, value=0)\n",
    "            )\n",
    "def visualize_cost_function(fixed_bias, mixing, shifting):\n",
    "    \"\"\"\n",
    "    Визуализируем поверхность целевой функции на (опционально) подпорченных данных и сами данные.\n",
    "    Портим данные мы следующим образом: сдвигаем категории навстречу друг другу, на величину, равную shifting \n",
    "    Кроме того, меняем классы некоторых случайно выбранных примеров на противоположнее.\n",
    "    Доля таких примеров задаётся переменной mixing\n",
    "    \n",
    "    Нам нужно зафиксировать bias на определённом значении, чтобы мы могли что-нибудь визуализировать.\n",
    "    Можно посмотреть, как bias влияет на форму целевой функции\n",
    "    \"\"\"\n",
    "    xlim = (min_w1, max_w1)\n",
    "    ylim = (min_w2, max_w2)\n",
    "    xx = np.linspace(*xlim, num=101)\n",
    "    yy = np.linspace(*ylim, num=101)\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.stack([xx, yy], axis=2)\n",
    "    \n",
    "    # не будем портить исходные данные, будем портить их копию\n",
    "    corrupted = data.copy()\n",
    "    \n",
    "    # инвертируем ответы для случайно выбранного поднабора данных\n",
    "    mixed_subset = np.random.choice(range(len(corrupted)), int(mixing * len(corrupted)), replace=False)\n",
    "    corrupted[mixed_subset, -1] = np.logical_not(corrupted[mixed_subset, -1])\n",
    "    \n",
    "    # сдвинем все груши (внизу справа) на shifting наверх и влево\n",
    "    pears = corrupted[:, 2] == 1\n",
    "    apples = np.logical_not(pears)\n",
    "    corrupted[pears, 0] -= shifting\n",
    "    corrupted[pears, 1] += shifting\n",
    "    \n",
    "    # вытащим наружу испорченные данные\n",
    "    global X_corrupted, y_corrupted\n",
    "    X_corrupted = np.hstack((np.ones((len(corrupted),1)), corrupted[:, :-1]))\n",
    "    y_corrupted = corrupted[:, -1].reshape((len(corrupted), 1))\n",
    "    \n",
    "    # посчитаем значения целевой функции на наших новых данных\n",
    "    calculate_weights = partial(J_by_weights, X=X_corrupted, y=y_corrupted, bias=fixed_bias)\n",
    "    J_values = np.apply_along_axis(calculate_weights, -1, points)\n",
    "    \n",
    "    fig = plt.figure(figsize=(16,5))\n",
    "    # сначала 3D-график целевой функции\n",
    "    ax_1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    surf = ax_1.plot_surface(xx, yy, J_values, alpha=0.3)\n",
    "    ax_1.set_xlabel(\"$w_1$\")\n",
    "    ax_1.set_ylabel(\"$w_2$\")\n",
    "    ax_1.set_zlabel(\"$J(w_1, w_2)$\")\n",
    "    ax_1.set_title(\"$J(w_1, w_2)$ for fixed bias = ${}$\".format(fixed_bias))\n",
    "    # потом плоский поточечный график повреждённых данных\n",
    "    ax_2 = fig.add_subplot(1, 2, 2)\n",
    "    plt.scatter(corrupted[apples][:, 0], corrupted[apples][:, 1], color = \"red\", alpha=0.7)\n",
    "    plt.scatter(corrupted[pears][:, 0], corrupted[pears][:, 1], color = \"green\", alpha=0.7)\n",
    "    ax_2.set_xlabel(\"yellowness\")\n",
    "    ax_2.set_ylabel(\"symmetry\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60aa8c09636d4f2e9df644de645516c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedFloatText(value=0.0, description='Enter $b$:', max=40.0, min=-40.0), BoundedFloat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(b=BoundedFloatText(value=str(g_bias), min=min_b, max=max_b, description=\"Enter $b$:\"),\n",
    "          w1=BoundedFloatText(value=\"0\", min=min_w1, max=max_w1, description=\"Enter $w_1$:\"),\n",
    "          w2=BoundedFloatText(value=\"0\", min=min_w2, max=max_w2, description=\"Enter $w_2$:\"),\n",
    "          learning_rate=Dropdown(options=[\"0.01\", \"0.05\", \"0.1\", \"0.5\", \"1\", \"5\", \"10\"], \n",
    "                                value=\"0.01\", description=\"Learning rate: \")\n",
    "         )\n",
    "def learning_curve_for_starting_point(b, w1, w2, learning_rate=0.1):\n",
    "    w = np.array([b, w1, w2]).reshape(X_corrupted.shape[1], 1)\n",
    "    learning_rate=float(learning_rate)\n",
    "    neuron = Neuron(w, activation_function=sigmoid, activation_function_derivative=sigmoid_prime)\n",
    "\n",
    "    story = [J_quadratic(neuron, X_corrupted, y_corrupted)]\n",
    "    for _ in range(2000):\n",
    "        neuron.SGD(X_corrupted, y_corrupted, 2, learning_rate=learning_rate, max_steps=2)\n",
    "        story.append(J_quadratic(neuron, X_corrupted, y_corrupted))\n",
    "    plt.plot(story)\n",
    "    \n",
    "    plt.title(\"Learning curve.\\n Final $b={0:.3f}$, $w_1={1:.3f}, w_2={2:.3f}$\".format(*neuron.w.ravel()))\n",
    "    plt.ylabel(\"$J(w_1, w_2)$\")\n",
    "    plt.xlabel(\"Weight and bias update number\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
